#!/usr/bin/env node

import { program } from 'commander';
import pg from 'pg';
import { MongoClient } from 'mongodb';
import * as fs from 'fs/promises';
import * as path from 'path';
import chalk from 'chalk';
import ora from 'ora';

const { Client } = pg;

// Constants
const VERSION = '0.1.0';
const CONNECTION_TIMEOUT = 10000; // 10 seconds
const SUPPORTED_DATABASES = {
  POSTGRES: ['postgresql://', 'postgres://'],
  MONGODB: ['mongodb://', 'mongodb+srv://'],
  MYSQL: ['mysql://', 'mariadb://'],
  MSSQL: ['mssql://', 'sqlserver://'],
  ORACLE: ['oracle://', 'oracledb://'],
} as const;

interface CommanderError extends Error {
  code?: string;
  exitCode?: number;
  nestedError?: Error;
}

interface SchemaOptions {
  dbString: string;
  filename?: string;
  directory?: string;
  timeout?: number;
}

interface MongoCollection {
  fields?: any[];
  indexes?: any[];
}

interface PostgresTable {
  columns?: any[];
  indexes?: any[];
}

interface PostgresSchema {
  tables?: Record<string, PostgresTable>;
  enums?: Record<string, any>;
}

function printHeader() {
  console.log(chalk.blue(`📦 schemix v${VERSION}`));
  console.log('Extract database schemas in a compact format for AI context windows\n');
}

function detectDatabaseType(connectionString: string): string | null {
  for (const [dbType, prefixes] of Object.entries(SUPPORTED_DATABASES)) {
    if (prefixes.some(prefix => connectionString.toLowerCase().startsWith(prefix))) {
      return dbType;
    }
  }
  return null;
}

function formatError(error: unknown, dbType: string | null): string {
  const baseError = error instanceof Error ? error.message : String(error);
  
  if (baseError.includes('password authentication failed')) {
    return 'Authentication failed: Invalid username or password';
  }
  
  if (baseError.includes('ECONNREFUSED')) {
    return `Could not connect to ${dbType || 'database'} server. Please check:\n` +
           chalk.yellow('1. The server is running\n') +
           chalk.yellow('2. The connection string is correct\n') +
           chalk.yellow('3. The port is accessible\n') +
           chalk.yellow('4. Network/firewall settings allow the connection');
  }
  
  if (baseError.includes('authentication failed')) {
    return `Authentication failed. Please verify:\n` +
           chalk.yellow('1. Username is correct\n') +
           chalk.yellow('2. Password is correct\n') +
           chalk.yellow('3. User has necessary permissions');
  }
  
  if (baseError.includes('timeout')) {
    return `Connection timed out after ${CONNECTION_TIMEOUT/1000} seconds.\n` +
           'Please check your network connection and try again.';
  }
  
  return `Database error: ${baseError}`;
}

function generateAIContextHeader(dbType: string): string {
  return `This file contains a database schema extraction in a compact format, optimized for AI context windows.
Generated by Schemix on: ${new Date().toISOString()}

================================================================
Schema Summary
================================================================

Purpose:
--------
This file contains a detailed representation of the database schema, designed
to be easily consumable by AI systems for analysis, querying assistance,
and other automated processes.

Schema Format:
-------------
The content is organized as follows:
1. This summary section
2. Database information
3. Schema details:
   - For PostgreSQL: Tables, columns, constraints, indexes, and enums
   - For MongoDB: Collections, fields, types, indexes, and sample data

Usage Guidelines:
----------------
- This schema representation is designed for read-only analysis
- When processing this schema, note that:
  * PostgreSQL: All objects are from the public schema
  * MongoDB: Field types are inferred from sampling
- Sensitive information (like credentials) has been removed

Notes:
------
- Schema extraction performed on: ${new Date().toLocaleDateString()}
- Database Type: ${dbType}
- Some system collections/tables may be excluded
- Indexes and constraints are included for comprehensive analysis

Additional Info:
---------------
For more information about Schemix, visit: https://github.com/yourusername/schemix

================================================================
Schema Details
================================================================

`;
}

function analyzeSchema(schema: string, dbType: string): Record<string, any> {
  const parsed = JSON.parse(schema) as PostgresSchema | MongoCollection[];
  const stats: Record<string, any> = {
    totalSize: schema.length,
    objectCount: 0,
    details: {}
  };

  if (dbType === 'POSTGRES') {
    const postgresSchema = parsed as PostgresSchema;
    const tables = Object.keys(postgresSchema.tables || {});
    const enums = Object.keys(postgresSchema.enums || {});
    
    stats.objectCount = tables.length;
    stats.details = {
      tables: tables.length,
      enums: enums.length,
      totalColumns: tables.reduce((acc: number, table: string) => 
        acc + (postgresSchema.tables?.[table].columns?.length || 0), 0),
      indexCount: tables.reduce((acc: number, table: string) => 
        acc + (postgresSchema.tables?.[table].indexes?.length || 0), 0)
    };
  } else if (dbType === 'MONGODB') {
    const collections = parsed as MongoCollection[];
    stats.objectCount = collections.length;
    stats.details = {
      collections: collections.length,
      totalFields: collections.reduce((acc: number, coll: MongoCollection) => 
        acc + (coll.fields?.length || 0), 0),
      totalIndexes: collections.reduce((acc: number, coll: MongoCollection) => 
        acc + (coll.indexes?.length || 0), 0)
    };
  }

  return stats;
}

async function getPostgresSchema(connectionString: string): Promise<string> {
  const client = new Client({ 
    connectionString,
    connectionTimeoutMillis: CONNECTION_TIMEOUT,
    ssl: connectionString.includes('?sslmode=require') ? { rejectUnauthorized: false } : undefined
  });
  
  const spinner = ora('Connecting to PostgreSQL database...').start();
  
  try {
    await client.connect();
    spinner.text = 'Extracting schema information...';

    const tablesResult = await client.query(`
      WITH table_info AS (
        SELECT 
          c.table_name,
          json_agg(
            json_build_object(
              'column', c.column_name,
              'type', c.data_type,
              'nullable', c.is_nullable,
              'default', c.column_default,
              'constraints', (
                SELECT json_agg(DISTINCT tc.constraint_type)
                FROM information_schema.table_constraints tc
                JOIN information_schema.constraint_column_usage ccu 
                  ON tc.constraint_name = ccu.constraint_name
                WHERE ccu.column_name = c.column_name 
                  AND ccu.table_name = c.table_name
              )
            ) ORDER BY c.ordinal_position
          ) as columns,
          obj_description(pgc.oid, 'pg_class') as description
        FROM information_schema.columns c
        JOIN pg_class pgc ON pgc.relname = c.table_name
        WHERE c.table_schema = 'public'
        GROUP BY c.table_name, pgc.oid
      ),
      index_info AS (
        SELECT 
          tablename as table_name,
          json_agg(
            json_build_object(
              'name', indexname,
              'definition', indexdef
            )
          ) as indexes
        FROM pg_indexes
        WHERE schemaname = 'public'
        GROUP BY tablename
      ),
      enum_info AS (
        SELECT 
          t.typname as enum_name,
          json_agg(e.enumlabel ORDER BY e.enumsortorder) as enum_values
        FROM pg_type t
        JOIN pg_enum e ON t.oid = e.enumtypid
        GROUP BY t.typname
      )
      SELECT 
        json_build_object(
          'tables', (SELECT json_object_agg(t.table_name, 
            json_build_object(
              'columns', t.columns,
              'description', t.description,
              'indexes', COALESCE(i.indexes, '[]'::json)
            )
          ) FROM table_info t
          LEFT JOIN index_info i ON t.table_name = i.table_name),
          'enums', (SELECT json_object_agg(enum_name, enum_values) FROM enum_info)
        ) as schema;
    `);

    spinner.succeed('Schema extracted successfully');
    return JSON.stringify(tablesResult.rows[0].schema, null, 0);
  } finally {
    await client.end();
  }
}

async function getMongoSchema(connectionString: string): Promise<string> {
  const client = new MongoClient(connectionString, {
    serverSelectionTimeoutMS: CONNECTION_TIMEOUT
  });
  
  const spinner = ora('Connecting to MongoDB database...').start();
  
  try {
    await client.connect();
    spinner.text = 'Analyzing collections...';
    
    const db = client.db();
    const collections = await db.listCollections().toArray();
    const schemas = [];
    
    for (const collection of collections) {
      spinner.text = `Analyzing collection: ${collection.name}...`;
      const sample = await db.collection(collection.name)
        .aggregate([{ $sample: { size: 5 } }])
        .toArray();
        
      if (sample.length > 0) {
        const schema = {
          collection: collection.name,
          fields: Array.from(new Set(sample.flatMap(doc => Object.keys(doc)))),
          types: Object.fromEntries(
            Object.keys(sample[0]).map(key => [
              key,
              sample.map(doc => typeof doc[key]).filter((v, i, a) => a.indexOf(v) === i)
            ])
          ),
          indexes: await db.collection(collection.name).indexes(),
          sampleData: sample[0]
        };
        schemas.push(schema);
      }
    }
    
    spinner.succeed('Schema extracted successfully');
    return JSON.stringify(schemas, null, 0);
  } finally {
    await client.close();
  }
}

async function writeSchemaToFile(schema: string, options: SchemaOptions, dbType: string | null): Promise<string> {
  const directory = options.directory || process.cwd();
  const filename = options.filename || 'schemix-out.txt';
  const fullPath = path.join(directory, filename);

  const header = generateAIContextHeader(dbType || 'UNKNOWN');
  const fullContent = header + schema;

  await fs.mkdir(directory, { recursive: true });
  await fs.writeFile(fullPath, fullContent, 'utf8');
  
  return fullPath;
}

function sanitizeConnectionString(str: string): string {
  str = str.replace(/^["'](.+)["']$/, '$1');
  
  try {
    const [baseUrl, ...queryParts] = str.split('?');
    const query = queryParts.join('?');
    
    const urlObj = new URL(baseUrl);
    
    if (urlObj.password) {
      urlObj.password = encodeURIComponent(decodeURIComponent(urlObj.password));
    }
    
    if (query) {
      return `${urlObj.toString()}?${query}`;
    }
    
    return urlObj.toString();
  } catch (error) {
    if (error instanceof TypeError && error.message.includes('Invalid URL')) {
      throw new Error('Invalid connection string format');
    }
    throw error;
  }
}

async function main(options: SchemaOptions) {
  try {
    printHeader();
    
    const dbType = detectDatabaseType(options.dbString);
    if (!dbType) {
      console.error(chalk.red('Error: Unsupported database type'));
      console.log('\nSupported database connection strings:');
      Object.entries(SUPPORTED_DATABASES).forEach(([db, prefixes]) => {
        console.log(`  ${chalk.green(db)}: ${prefixes.join(', ')}`);
      });
      process.exit(1);
    }
    
    console.log(`Database type: ${chalk.green(dbType)}`);
    
    const startTime = Date.now();
    let schema: string;

    if (SUPPORTED_DATABASES.MONGODB.some(prefix => options.dbString.startsWith(prefix))) {
      schema = await getMongoSchema(options.dbString);
    } else if (SUPPORTED_DATABASES.POSTGRES.some(prefix => options.dbString.startsWith(prefix))) {
      schema = await getPostgresSchema(options.dbString);
    } else {
      throw new Error(`${dbType} support is coming soon!`);
    }

    const stats = analyzeSchema(schema, dbType || 'UNKNOWN');
    const outputPath = await writeSchemaToFile(schema, options, dbType);
    const duration = ((Date.now() - startTime) / 1000).toFixed(2);
    
    console.log(chalk.blue('\n📊 Schema Analysis:'));
    console.log('──────────────────────');
    
    if (dbType === 'POSTGRES') {
      console.log(`Tables: ${stats.details.tables}`);
      console.log(`Total Columns: ${stats.details.totalColumns}`);
      console.log(`Indexes: ${stats.details.indexCount}`);
      console.log(`Enums: ${stats.details.enums}`);
    } else if (dbType === 'MONGODB') {
      console.log(`Collections: ${stats.details.collections}`);
      console.log(`Total Fields: ${stats.details.totalFields}`);
      console.log(`Total Indexes: ${stats.details.totalIndexes}`);
    }

    console.log(chalk.blue('\n📈 Summary:'));
    console.log('────────────');
    console.log(`Database: ${dbType}`);
    console.log(`Duration: ${duration}s`);
    console.log(`Output: ${outputPath}`);
    console.log(`Schema Size: ${(schema.length / 1024).toFixed(2)} KB`);
    
    if (schema.toLowerCase().includes('user') || schema.toLowerCase().includes('auth')) {
      console.log(chalk.yellow('\n⚠️  Security Notice:'));
      console.log('───────────────────');
      console.log('Schema contains potentially sensitive tables/collections.');
      console.log('Ensure proper handling of the output file.');
    }

    console.log(chalk.green('\n🎉 All Done!'));
    console.log('Your schema has been successfully extracted and formatted for AI context.');

  } catch (error) {
    const dbType = detectDatabaseType(options.dbString);
    const errorMessage = formatError(error, dbType);
    console.error(chalk.red('\nError:'), errorMessage);
    process.exit(1);
  }
}

program
  .name('schemix')
  .description(
    'schemix - Extract and compact database schemas for AI context windows\n\n' +
    'Example usage:\n' +
    '  $ schemix "postgresql://user:password@localhost:5432/dbname"\n' +
    '  $ schemix "mongodb://user:password@localhost:27017/dbname"\n\n' +
    'Supported databases:\n' +
    '  - PostgreSQL (postgresql://, postgres://)\n' +
    '  - MongoDB (mongodb://, mongodb+srv://)\n' +
    '  - MySQL (coming soon)\n' +
    '  - MSSQL (coming soon)\n' +
    '  - Oracle (coming soon)'
  )
  .version(VERSION, '-v, --version', 'Output the current version')
  .argument('<db-string>', 'Database connection string (must be wrapped in quotes)')
  .option('-f, --filename <name>', 'Output filename (default: schemix-out.txt)')
  .option('-d, --directory <path>', 'Output directory (default: current directory)')
  .option('-t, --timeout <ms>', 'Connection timeout in milliseconds (default: 10000)')
  .addHelpText('after', '\n' + chalk.yellow('Important:') + 
    ' Connection string must be wrapped in quotes:\n' +
    '  $ schemix "postgresql://user:pass@localhost:5432/db"\n' +
    '  $ schemix "postgresql://user:pass@localhost:5432/db?schema=public"\n')
  .configureOutput({
    writeOut: (str) => process.stdout.write(str),
    writeErr: (str) => process.stdout.write(str),
    outputError: (str, write) => write(str)
  })
  .action((dbString, options) => {
    try {
      if (program.opts().help || program.opts().version) {
        return;
      }

      const sanitizedDbString = sanitizeConnectionString(dbString);
      main({
        dbString: sanitizedDbString,
        filename: options.filename,
        directory: options.directory,
        timeout: options.timeout ? parseInt(options.timeout) : CONNECTION_TIMEOUT
      });
    } catch (err: unknown) {
      const errorMessage = err instanceof Error ? err.message : String(err);
      
      if (err instanceof Error && errorMessage.includes('Invalid URL')) {
        console.error(chalk.red('\nError: Invalid connection string format'));
        console.log('\nCorrect formats:');
        console.log('  $ schemix "postgresql://user:password@localhost:5432/dbname"');
        console.log('  $ schemix "mongodb://user:password@localhost:27017/dbname"\n');
      } else {
        console.error(chalk.red('\nError:'), errorMessage);
      }
      process.exit(1);
    }
  });

process.on('uncaughtException', (err: Error) => {
  const commanderErr = err as CommanderError;
  if (commanderErr.code === 'commander.helpDisplayed' || commanderErr.code === 'commander.version') {
    process.exit(0);
  }
  console.error(chalk.red('Error:'), err.message);
  process.exit(1);
});

program.parse();